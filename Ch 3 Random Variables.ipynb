{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8fbe39-0e0b-4cf9-beb9-ab5255d7e904",
   "metadata": {},
   "source": [
    "# Chapter 3: Random Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef474ea4-ddec-42b9-aa96-be0381102880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source of the content is freely available online\n",
    "# https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view\n",
    "# https://projects.iq.harvard.edu/stat110/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a9861d-da0a-4c08-baa2-cb791f0bf79c",
   "metadata": {},
   "source": [
    "<h4>Definition 3.1.1 (Random Variable)</h4>\n",
    "\n",
    "Given an experiment with sample space $S$, a random variable is a function from the sample space $S$ to the real numbers $\\mathbb{R}$. Thus, a random variable assigns a numerical value $X(s)$ to each possible outcomes of the experiment.\n",
    "\n",
    "$P(B|E) = \\sum_{i=1}^n P(B|A_i, E) P(A_i, E)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd27392-c6d9-4c8f-9a9f-ddf0d11e0e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478495fc-484e-4103-ada9-4a43debdd71f",
   "metadata": {},
   "source": [
    "<h4>Story 3.3.3 (Bernoulli Trial)</h4>\n",
    "\n",
    "An experiment that can result in either a success or failure, and not both, is a Bernoulli trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75ae990-c60a-4685-9fd3-7a3c7d8f3b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9edda86f-2e1c-4a6c-adf2-75b3fa4191e5",
   "metadata": {},
   "source": [
    "<h4>Story 3.3.4 (Binomial Distribution)</h4>\n",
    "\n",
    "Suppose that n independent Bernoulli trials are performed, each with the same success probability p. Let X be the number of successes. The distribution of X is called the Binomial distribution, with parameters of n and p.\n",
    "\n",
    "$P(X=k) = \\binom{n}{k} p^k(1-p)^{n-k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d4be0-2dcb-4145-abe7-5926e9646434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55a02469-a53b-4282-939e-d31d57c4e3d6",
   "metadata": {},
   "source": [
    "<h4>Story 3.4.1 (Hypergeometric Distribution)</h4>\n",
    "\n",
    "Consider an urn with $w$ white balls and $b$ black balls. We draw $n$ balls out of the urn at random without replacement, such that all $\\binom{w+b}{n}$ samples are equally likely. Let $X$ be the number of white balls in the sample. Then $X$ is said to have the Hypergeometric distribution with parameters $w$, $b$, and $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6bf98-1e16-44b2-b507-0ecb573e3e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04b50a57-cbb5-4e73-b6ad-361ce7fed0a4",
   "metadata": {},
   "source": [
    "<h4>Theorem 3.4.1 (Hypergeometric PMF)</h4>\n",
    "\n",
    "If $X \\text{~} Geom(w,b,n)$, then with all samples equally likely, the PMF of $X$ is:\n",
    "\n",
    "$P(X=k) = \\frac{ \\binom{w}{k} \\binom{b}{n-k} }{ \\binom{w+b}{n} } $\n",
    "\n",
    "for integers satisfying $0 \\le k \\le w$ and $0 \\le n-k \\le b$, and $P(X=k)=0$ otherwise.\n",
    "\n",
    "This PMF is valid because the numerator, summed over all $k$, equals $\\binom{w+b}{n}$ by Vandermonde's identity.\n",
    "\n",
    "The essential structure of the Hypergeometric story is that items in a population are classified using two sets of tags. Furthermore, at least one of these sets of tags is assigned completely at random (like the balls sampled randomly from the urn). Then, $X \\text{~} HGeom(w,b,n)$ represents the number of twice-tagged items (e.g., balls that are both white and sampled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c0493-1236-4611-87bc-73b43d6227aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a67a6a5-b49a-4080-991d-88371a704343",
   "metadata": {},
   "source": [
    "<h4>Example 3.4.3 (Elk Capture-Recapture)</h4>\n",
    "\n",
    "A forest has $N$ elk. Today, $m$ of the elk are captured, tagged, and released into the wild. At a later date, $n$ elk are recaptured at random. Assume that the recaptured elk are equally likely to be any set of $n$ of the elk.\n",
    "\n",
    "By the story of the Hypergeometric, the number of tagged elk in the recaptured sample is $HGeom(m, N-m, n)$. The m tagged elk correspond to the white balls and the $N-m$ untagged elk correspond to the black balls. Instead of sampling $n$ balls from the urn, we recapture $n$ elk from the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ac50f-929d-48c5-9ee0-f8ab74a00ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d668d17-c123-4c41-bef6-7d3455bdfe66",
   "metadata": {},
   "source": [
    "<h4>Example 3.4.4 (Aces in a Poker Hand)</h4>\n",
    "\n",
    "In a 5-card hand drawn at random, the number of aces in the hand was the $HGeom(4,48,5)$ distribution, which can $b$ seen by thinking of the aces as white balls and the non-aces as black balls.\n",
    "\n",
    "$\\frac{ \\binom{4}{3} \\binom{48}{2} }{ \\binom{52}{5} } \\approx 0.0017$\n",
    "\n",
    "<table class=\"tableizer-table\">\n",
    "<thead><tr class=\"tableizer-firstrow\"><th>Story</th><th>First Set of Tags</th><th>Second Set of Tags</th></tr></thead><tbody>\n",
    " <tr><td>Urn</td><td>White, Black</td><td>Sampled, Not Sampled</td></tr>\n",
    " <tr><td>Elk</td><td>Tagged, Untagged</td><td>Recaptured, Not Recaptured</td></tr>\n",
    " <tr><td>Cards</td><td>Cards, Ace</td><td>In Hand, Not in Hand</td></tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc516117-2ab9-4f5b-bd3f-6c443faa8f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90a9b782-1227-4bd4-9746-9fa4442b52ee",
   "metadata": {},
   "source": [
    "<h4>Theorem 3.4.5</h4>\n",
    "\n",
    "The $HGeom(w,b,n)$ and $HGeom(n, s+b-n, w)$ distributions are identical.\n",
    "\n",
    "<h5>Binomial vs. Hypergeometric</h5>\n",
    "\n",
    "The Binomial and Hypergeometric distributions are often confused. Both can be interpreted as the number of successes in $n$ Bernoulli trials. For the Hypergeometric, each tagged elk in the recaptured sample can be considered a success and each untagged elk a failure. However, in the Binomial story the Bernoulli trials are independent, and in the Hypergeometric story are dependent, since the sampling is done without replacement. Knowing that one elk in our sample is tagged decreases the probability that the second elk will also be tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7f9a2-83c9-46c1-aec4-e9377ddfd44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d956c20f-35fb-4752-b6b0-e021112bdd5d",
   "metadata": {},
   "source": [
    "<h4>3.8 Independence of Random Variables</h4>\n",
    "\n",
    "Random variables $X$ and $Y$ are said to be independent if $P(X \\le x, Y \\le Y) = P(X \\le x) P(Y \\le y)$\n",
    "\n",
    "In the discrete case, this is equivaleent to the condition:\n",
    "\n",
    "$P(X=x, Y=y) = P(X=x)P(Y=y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f131d-a754-4fd3-a3d2-52e7f301ae74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca78d7da-a1c8-482f-a109-4c41ea961b25",
   "metadata": {},
   "source": [
    "<h4>Definition 3.8.2 (Independence of Many Random Variables)</h4>\n",
    "\n",
    "Random variables $X_1, \\ldots, X_n$ are independent if \n",
    "\n",
    "$P(X_1 \\le x_1, \\ldots, X_n \\le x_n) = P(X_1 \\le x_1, \\ldots, P(X_n \\le x_n))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db49442-941f-41d1-9e08-0ec7397a27d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0a3af4-f3a9-4caf-b678-f93badeced40",
   "metadata": {},
   "source": [
    "<h4>Theorem 3.8.5 (Functions of Random Variables)</h4>\n",
    "\n",
    "If $X$ and $Y$ are independent random variables $X$ and $Z$, the function $P(X=x | Z=x)$, when considered as a function of $x$ for fixed $z$, is called the conditional PMF of $X$ given $Z=z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796eb8c0-b6c6-4448-90d2-f56610a69afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b47b2dda-3eb8-4c3f-af88-f57ad75ab467",
   "metadata": {},
   "source": [
    "<h4>Definition 3.8.6 (IID)</h4>\n",
    "\n",
    "Random variables that are independent and have the same distribution are called independent and identically distributed, or IID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55aa4e-d1c6-4237-8270-77208670032e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a1d5ddf-7812-43f3-a2e2-c04c6b63705b",
   "metadata": {},
   "source": [
    "<h4>Definition 3.8.11</h4>\n",
    "\n",
    "For any discrete random variables $X$ and $Z$, the function $P(X=x|Z=z)$, when considered as a function of $x$ for fixed $z$, is called the conditional PMF of $X$ given $Z=z$.\n",
    "\n",
    "Independence of random variables does not imply conditional independence, nor vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79560f42-9dc3-4af8-8a3f-44a0a2eed4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "402d2403-922d-4367-b8f6-7de38f5ee9ad",
   "metadata": {},
   "source": [
    "<h4>Example 3.8.12 (Matching Pennies)</h4>\n",
    "\n",
    "Each of two players, $A$ and $B$, has a fair penny. They flip their pennies independently. If the pennies match, $A$ wins; otherwise, $B$ wins. Let $X$ be $1$ if $A$'s penny lands heads and $-1$ otherwise, and define $Y$ similarly for $B$.\n",
    "\n",
    "Let $Z=XY$, which is $1$ if $A$ wins and $-1$ if $B$ wins. Then $X$ and $Y$ are unconditionally independent, but given $Z=1$, we know that $X=Y$, so $X$ and $Y$ are conditionally dependent given $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa841f-d036-444a-8572-41a00952ee58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c28e7837-94de-4069-a39e-a750c7065658",
   "metadata": {},
   "source": [
    "<h4>Example 3.8.13 (Two Friends)</h4>\n",
    "\n",
    "Consider the \"I only have two friends who call me\" scenario from example 2.5.11. Le $X$ be the indicator of Alice calling me next Friday, $Y$ be the indicator of Bob calling me next Friday, and $Z$ be the indicator of exactly one of them calling next Friday. Then $X$ and $Y$ are independent (by assumption). But given $Z=1$, we have that $X$ and $Y$ are completely dependent: given that $Z=1$, we have $Y=1-X$.\n",
    "\n",
    "Next we'll see why conditional independence does not imply independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ef460-9dd9-43d2-a188-03e19cd1e91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6686c7-5be0-4701-94ba-4439f5020a31",
   "metadata": {},
   "source": [
    "<h4>Example 3.8.14 (Mystery Opponent)</h4>\n",
    "\n",
    "Suppose you are going to play two games of tennis against one of two identical twins. Against one, you are evenly matched, and against the other, you have a $3/4$ chance of winning.\n",
    "\n",
    "Suppose that you can't tell which twin you are playing against until after the two games. Let $Z$ be the indicator of playing against the twin with whom you're evenly matched, and let $X$ and $Y$ be the indicators of victory in the first and second games respectively.\n",
    "\n",
    "Conditional on $Z=1$, $X$ and $Y$ are IID Bern(1/2), and conditional on $Z=0$, $X$ and $Y$ are IID $Bern(3/4)$. So $X$ and $Y$ are conditionally independent given $Z$. Unconditionally, $X$ and $Y$ are dependent because observing $X=1$ makes it more likely that we are playing the twin who is worse. That is, $P(Y=1, X=1) \\gt P(Y=1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f862cad-f29d-42b6-8ce1-982518796345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb546ff-0c14-4d97-9bee-83a3bad1f4ad",
   "metadata": {},
   "source": [
    "<h3>Connections Between Binomial and Hypergeometric</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60169f13-fa7c-4299-9ccb-0ca34a94275c",
   "metadata": {},
   "source": [
    "<h4>Theorem 3.9.2</h4>\n",
    "\n",
    "If $X \\text{~} Bin(n,p)$, $Y \\text{~} Bin(m,p)$, and $X$ is independent of $Y$, then the conditional distribution of $X$ given $X+Y=r$ is $HGeom(n,m,r)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b4d78-adf0-4fd3-a0f9-547178bf463f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2161268-1246-4ef4-9c0c-c563d5241709",
   "metadata": {},
   "source": [
    "<h4>Linearity of Expectation</h4>\n",
    "\n",
    "The expected value of a sum of random variables is the sum of the individual expected values.\n",
    "\n",
    "<h4>Theorem 4.2.1 (Linearity of Expectation)</h4>\n",
    "\n",
    "For any random variables $X$, $Y$, and any constant $c$, \n",
    "\n",
    "$E(X+Y) = E(X) + E(Y)$\n",
    "$E(cX) = cE(X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28670105-1723-4ffc-a669-c0d49e4dd7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82070d-eb94-4973-a14e-a19d8b3627ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2721940a-6585-4599-8194-bc08bc369696",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99288948-c2a0-4e99-80c3-ee143e0ca8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(subtitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911ad97-92cb-4fa8-9ad7-d66a7946c2e7",
   "metadata": {},
   "source": [
    "<h4>Exercise 18</h4>\n",
    "\n",
    "In the World Series, two baseball teams play a sequence of games against each other, and the first to win $4$ games wins the series. Let $p$ be the probability that $A$ wins an individual game, and assume the games are independent. What is the probability that team $A$ wins the series?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Let $q=1-p$. First, let us do a direct calculation.\n",
    "\n",
    "$P(\\text{A Wins}) = $\n",
    "\n",
    "$P(\\text{A wins in 4 games}) + $\n",
    "\n",
    "$P(\\text{A wins in 5 games}) + $\n",
    "\n",
    "$P(\\text{A wins in 6 games}) + $\n",
    "\n",
    "$P(\\text{A wins in 7 games})$\n",
    "\n",
    "</br>\n",
    "\n",
    "$= p^4 + \\binom{4}{3} p^4q + \\binom{5}{3} p^4 q^2 + \\binom{6}{3} p^4 q^3$\n",
    "\n",
    "</br>\n",
    "\n",
    "For intuition, note for example that:\n",
    "\n",
    "$P(\\text{A wins in 5}) = P(\\text{A wins 3 of first}  4) \\cdot P(\\text{A wins } 5^{th} | \\text{A wins 3 of first 4})$\n",
    "$P(\\text{A wins in 5}) = \\binom{4}{3} p^3 qp$\n",
    "\n",
    "A neater solution is to use the fact that we can assume that the teams play all $7$ games no matter what. Let $X$ be the number of wins for team $A$, so that $X \\text{~} Bin(7,p)$. Then:\n",
    "\n",
    "$P(X \\ge 4) = P(X=4) + P(X=5) + \\ldots + P(X=7)$\n",
    "\n",
    "$P(X \\ge 4) = \\binom{7}{4} p^4 q^3 + \\binom{7}{5} p^5 q^2 + \\binom{7}{6} p^6q + p_7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf834a9-bd1c-4ce8-b425-a14f49e6757b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8bf8fca-e607-4204-9872-d3d66acf64dc",
   "metadata": {},
   "source": [
    "<h4>Exercise 28</h4>\n",
    "\n",
    "There are $n$ eggs, each of which hatches a chick with probability $p$, independently. What is the distribution of the number of chicks that hatch? What is the distribution of the number of chicks that survive?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Let $H$ be the number of eggs that hatch and $X$ be the number of hatchlings that survive. Each egg is a Bernoulli trial where H represents a success in terms of hatching, and $X$ is a success in terms of surviving. By the story of the Binomial, $H \\text{~} Bin(n,p)$ with PMF:\n",
    "\n",
    "$P(H=k) = \\binom{n}{k} p^k(1-p^{n-k})$\n",
    "\n",
    "The eggs independently have probability pr each of hatching a chick that survives. By the story of the Binomial, we have $X \\text{~} Bin(n,pr)$ with PMF:\n",
    "\n",
    "$P(X=k) = \\binom{n}{k} (pr)^k (1-pr)^{n-k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5092698-24b1-4804-8475-cf1878ba1a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f667b69-8cb5-45ad-b4f8-32a17293db8c",
   "metadata": {},
   "source": [
    "<h4>Exercise 37</h4>\n",
    "\n",
    "A message is sent over a noisy channel. The message is a sequence of n bits ($x_i \\in \\{0,1\\}$). Assume that the error events are independent. Let $p$ be the probability that an individual bit has an error ($0 \\lt p \\lt \\frac{1}{2}$). Let $y_1, y_2, \\ldots, y_n$ be the received message (so $y_i = x_i$ if there is no error in that bit).\n",
    "\n",
    "To help detect errors, the $n^{th}$ bit is reserved for a parity check; $x_n$ is defined to be 0 if $x_1 + x_2 + \\ldots + x_{n-1}$ is even, and 1 of $x_1 + x_2 + \\ldots + x_{n-1}$ is odd. When the message is received, the recipient checks whether $y_n$ has the same parity as $y_1 + y_2 + \\ldots + y_{n-1}$. If the parity is wrong, the recipient knows that at least one error occurred; otherwise, the recipient assumes that there were no errors.\n",
    "\n",
    "<b>Part A:</b>\n",
    "\n",
    "For $n=5$, $p=0.1$, what is the probability that the received message has errors which go undetected?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Note that $\\sum_{i=1}^n x_i$ is even. If the number of errors is even and nonzero, the errors will go undetected; otherwise, $\\sum_{i=1}^n y_i$ will be odd, so the errors will be detected. The number of errors is $Bin(n,p)$, so the probability of undetected errors when $n=5$, $p=0.1$ is:\n",
    "\n",
    "$\\binom{5}{2} p^2 (1-p)^3 + \\binom{5}{4} p^4 (1-p) \\approx 0.073$\n",
    "\n",
    "<b>Part B:</b>\n",
    "\n",
    "For general $n$ and $p$, write down an expression (as a sum) for the probability that the received message has errors which go undetected.\n",
    "\n",
    "<i>Answer:<i/>\n",
    "\n",
    "By the same reasoning as in part A, the probability of undetected errors is:\n",
    "\n",
    "$\\sum_{k ~even, ~k \\ge 2} \\binom{n}{k} p^k (1-p)^{n-k}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
