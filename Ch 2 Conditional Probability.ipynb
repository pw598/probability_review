{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36780e05-b87c-456d-a7cb-246b5c4eb3c8",
   "metadata": {},
   "source": [
    "# Chapter 2: Conditional Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38c744-1555-4a0a-b8ee-4ee8dca89a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source of the content is freely available online\n",
    "# https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view\n",
    "# https://projects.iq.harvard.edu/stat110/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e502e0-f686-472c-8ce3-d132eed97b65",
   "metadata": {},
   "source": [
    "<h4>Definition 2.2.1 (Conditional Probability)</h4>\n",
    "\n",
    "If $A$ and $B$ are events with $P(B) \\gt 0$, then the conditional probability of $A$ given $B$, $P(A|B)$, is:\n",
    "\n",
    "$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$\n",
    "\n",
    "$A$ is the prior probability of $A$ and $P(A|B)$ the posterior probability of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b55916-6a54-45ab-a278-9247cb909a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b10cab9-d4dc-4393-980f-a7468d726ceb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Example 2.2.2. (Two Cards)</h4>\n",
    "\n",
    "Two cards are drawn randomly, one at a time without replacement. Let $A$ be the event that the first card is a heart, and $B$ be the event that the second card is red. Find $P(A|B)$ and $P(B|A)$.\n",
    "\n",
    "Answer:\n",
    "\n",
    "By the naive definition of probability and the multiplication rule:\n",
    "\n",
    "$P(A \\cap B) = \\frac{13 \\cdot 25}{52 \\cdot 51} = \\frac{25}{204}$\n",
    "\n",
    "since a favorable outcome is determined by choosing any of the $13$ hearts and then any of the remaining $25$ red cards. Also, $P(A) = \\frac{1}{4}$ since the $4$ suits are equally likely, and \n",
    "\n",
    "$P(B) = \\frac{26 \\cdot 51}{52 \\cdot 51} = \\frac{1}{2}$\n",
    "\n",
    "since there are $26$ favorable possibilities for the second card, and for each of those, the first card can be any other card.\n",
    "\n",
    "A neater way to see that $P(B) = \\frac{1}{2}$ is by symmetry - from a vantage point before having done the experiment, the second card is equally likely to be any card in the deck.\n",
    "\n",
    "We now have all the pieces needed to apply the definition of conditional probability.\n",
    "\n",
    "$P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{25/204}{1/2}$\n",
    "$P(B|A) = \\frac{P(B \\cap A)}{P(A)} = \\frac{25/204}{1/4} = \\frac{25}{51}$\n",
    "\n",
    "There are several things worth noting:\n",
    "\n",
    "1. It's important to be careful about which events to put on which side of the conditioning bar, $P(A|B) \\neq P(B|A)$. Confusing these two quantities is the 'prosecutor's fallacy'.\n",
    "\n",
    "2. The chronological order in which cards were chosen does not dictate which conditional probabilities we can look at. Imagine that someone spreads out the cards and draws one cared with their left hand and another card with their right hand, at the same time. Defining $A$ and $B$ based on the right hand's card rather than the first and second card would not change the structure of the problem in any important way.\n",
    "\n",
    "3. We can see that $P(B|A) = \\frac{25}{51}$ by a direct interpretation of what conditional probability means: if the first card drawn is a heart, then the remaining cards consist of $25$ red cards and $26$ black cards, and the conditional probability of getting a red card is $25/(25+26) = 25/51$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb845f0-8706-4641-b13b-54ab8146bc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfdb11ad-8f8a-4f5c-9071-9a73990c610d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Example 2.2.5 (Two Children)</h4>\n",
    "\n",
    "Mr. Jones has two children. the older child is a girl. What is the probability that both children are girls?\n",
    "\n",
    "Mr. Smith has two children. At least one of them is a boy. What is the probability that both children are boys?\n",
    "\n",
    "Answer:\n",
    "\n",
    "The definition of conditional probability gives:\n",
    "\n",
    "$P(\\text{both girls | elder is girl}) = \\frac{ P(\\text{both girls, elder is girl}) }{ P(\\text{elder is girl}) } = \\frac{1/4}{1/2} = \\frac{1}{2}$\n",
    "\n",
    "$P(\\text{both girls | at least one girl}) = \\frac{P(\\text{both girls, at least one girl})}{P(\\text{at least one girl})} = \\frac{1/4}{3/4} = \\frac{1}{3}$\n",
    "\n",
    "By symmetry:\n",
    "\n",
    "$P(\\text{both girls | younger is girl}) = P(\\text{both girls | elder is girl}) = \\frac{1}{2}$\n",
    "\n",
    "However, there is no such symmetry between the conditional probabilities $P(\\text{both girls | elder is girl})$ and $P(\\text{GG | at least one girl})$. Saying that the elder is a girl designates a specific child, and then the other child (the younger) has a $50\\%$ chance of being a girl.\n",
    "\n",
    "Conditioning on a specific child being a girl knocks away $2$ of the $4$ 'pebbles' in the sample space of $\\{GG, GB, BG, BB\\}$, where $GB$ means the elder child is a girl and the younger child is a boy. In contrast, conditioning on at least once child being a girl knocks away only BB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c401fd2-e6b3-4f7c-a1db-e660f28ad993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ef536d-3141-4923-9436-f2ccff42d6fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Example 2.2.6 (Random Child is a Girl)</h4>\n",
    "\n",
    "A family has two children. You randomly run into one of the two, and learn that she is a girl. What is the conditional problem that both are girls?\n",
    "\n",
    "Let $G_1$, $G_2$, and $G_3$ be the events that the elder, younger, and random child is a girl, respectively. By assumption, $P(G_1) = P(G_2) = P(G_3) = 1/2$. By the naive definition of probability, we have:\n",
    "\n",
    "$P(G_1 \\cap G_2 | G_3) = P(G_1 \\cap G_2 \\cap G_3) / P(G_3) = \\frac{1}{4} \\frac{1}{2} = \\frac{1}{2}$\n",
    "\n",
    "because $G_1 \\cap G_2 \\cap G_3 = G_1 \\cap G_2$. If both children are girls, it guarantees that the random child is a girl.\n",
    "\n",
    "Keep in mind that to arrive at $\\frac{1}{2}$, an assumption is needed about how the random child was selected. We have collected a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b76ea-6b56-401d-ad92-3a954cfab094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a84107e-2254-4749-9e7d-4e1bd2072076",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Example 2.2.7 (A Girl Born in Winter)</h4>\n",
    "\n",
    "A family has two children. Find the probability that both children are girls, given that at least one of the two is a girl who was born in winter. Assume gender is independent of season.\n",
    "\n",
    "Answer:\n",
    "\n",
    "$P(\\text{both girls | at least one winter girl}) = \\frac{ P(\\text{both girls, at least one winter girl}) }{P(\\text{at least one winter girl})}$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$P(\\text{both girls | at least one winter girl}) = \\frac{ \\left( \\frac{1}{4} \\right) \\left( 1-\\left(\\frac{3}{4} \\right)^2 \\right) }{ 1-(7/8)^2 } = \\frac{7/64}{15/64} = \\frac{7}{15}$\n",
    "\n",
    "The result in example 2.2.5 is that the conditional probability of both children being girls, given that at least one is a girl, is $\\frac{1}{3}$. Why should it be any different when we learn that at least one is a winter-born girl?\n",
    "\n",
    "Conditioning on more and more specific information brings the probability closer and closer to $\\frac{1}{2}$.\n",
    "\n",
    "Condtioning on \"at least one girl born on March 31\" comes very close to specifying a child. The seemingly irrelevant information such as season of birth interpolates between the two parts of example 2.2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347e758-ddf9-49aa-be8f-f603561b4a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ced290e-22f9-4034-b785-355fc37e802d",
   "metadata": {},
   "source": [
    "<h3>Bayes' Rule and the LOTP</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db1f871-fe9c-4d0b-a1a4-286ec958a7b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Theorem 2.3.1 (Probability of the Intersection of Two Events)</h4>\n",
    "\n",
    "For any events $A$ and $B$ with positive probabilities:\n",
    "\n",
    "$P(A \\cap B) = P(B)P(A|B) = P(A) P(B|A)$\n",
    "\n",
    "This follows from taking the definition of $P(A|B)$ and multiplying both sides by $P(B)$, and then taking the definition of $P(B|A)$ and multiplying both sides by $P(A)$.\n",
    "\n",
    "Applying theorem 2.3.1 repeatedly, we can generalize to the intersection of $n$ events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b7ca7-b1a1-4694-ae23-afb40232b207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77dd1c51-784c-4cd8-a895-65c1fc2b23c3",
   "metadata": {},
   "source": [
    "<h4>Theorem 2.3.2 (Probability of the Intersection of $n$ Events)</h4>\n",
    "\n",
    "For any events $A_1, \\ldots, A_n$ with $P(A_1, A_2, \\ldots, A_{n-1}) > 0$, \n",
    "\n",
    "$P(A_1, A_2, \\ldots, A_n) = P(A_1) P(A_2 | A_1) P(A_3 | A_1, A_2) \\ldots P(A_n | A_1, \\ldots, A_{n-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee63b07-14da-4198-af00-057c233eebf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Theorem 2.3.3. (Bayes' Rule)</h4>\n",
    "\n",
    "Bayes' Rule can be derived as follows:\n",
    "\n",
    "$P(A|B)P(B) = P(B|A)P(A)$\n",
    "$P(A|B) = \\frac{ P(B|A) P(A) }{P(B)}$\n",
    "\n",
    "Another way to work with Bayes' rule is in terms of odds rather than probability.\n",
    "\n",
    "$\\frac{P(A|B)}{P(A^C | B)} = \\frac{P(B|A)}{P(B|A^C)} \\frac{P(A)}{P(A^C)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825602c6-f452-499d-8be6-d3e3c99cf880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c94ad54-5d39-4c9e-9633-16a8df54ee5c",
   "metadata": {},
   "source": [
    "<h4>Theorem 2.3.6 (Law of Total Probability)</h4>\n",
    "\n",
    "Let $A_1, \\ldots, A_n$ be a partition of the sample space $S$ (i.e., the $A_i$ are disjoint events and their union is $S$), with $P(A) \\gt 0$ for all $i$. Then, $P(B) = \\sum_{i=1}^n P(B|A_i)P(A_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f539245e-29e6-4e40-bc8f-a98e3119195e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4cd56c-26b0-49b4-a0b1-338b0af242e7",
   "metadata": {},
   "source": [
    "<h4>Example 2.3.7 (Random Coin)</h4>\n",
    "\n",
    "You have one fair coin and one biased coin which lands heads with probability $\\frac{3}{4}$. You pick one of the coins at random and flip it $3$ times. It lands heads all $3$ times. What is the probability that the coin you picked is the fair one?\n",
    "\n",
    "Let $F$ be the event that the fair coin is picked, and and $A$ be the event that $3$ heads are flipped.\n",
    "\n",
    "$P(F|A) = \\frac{ P(A|F) P(F) }{P(A)}$\n",
    "\n",
    "$P(F|A) = \\frac{ P(A|F P(F)) }{ P(A|F) P(F) + P(A|F^C) P(F^C) }$\n",
    "\n",
    "$P(F|A) = \\frac{ \\left( \\frac{1}{2} \\right)^3 \\cdot \\frac{1}{2} }{\\left( \\frac{1}{2} \\right)^3 \\cdot \\frac{1}{2}} + \\left( \\frac{3}{4} \\right)^3 \\cdot \\frac{1}{2} \\approx 0.23$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb05a00-945d-40ee-91fa-938ec4625d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b759664-c91a-4bfb-a218-bbf46db5eca3",
   "metadata": {},
   "source": [
    "<h4>Example 2.3.9 (Testing for a Rare Disease)</h4>\n",
    "\n",
    "Fred is tested for a disease which afflicts $1\\%$ of the population, and the test is positive. Let $D$ be the event that Fred has the disease, and $T$ be the event that he tests positive.\n",
    "\n",
    "The test is $95\\%$ accurate, in this case meaning $P(T|D) = 0.95 and P(T^C|D^C) = 0.95$ (the quantity $P(T|D)$ is the sensitivity or $TPR$, and $P(T^C|D^C)$ is known as the specificity or $TNR$)\n",
    "\n",
    "Find the conditional probability that Fred has the disease, given the positive test result.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Applying Bayes' rule and the law of total probability:\n",
    "\n",
    "$P(D|T) = \\frac{ P(T|D) P(D) }{P(T)}$\n",
    "$P(D|T) = \\frac{ P(T|D) P(D) }{ P(T|D)P(D) + P(T|D^C) P(D^C) }$\n",
    "$P(D|T) = \\frac{ 0.95 \\cdot 0.01 }{ 0.95 \\cdot 0.01 + 0.05 \\cdot 0.99 } \\approx 0.16$\n",
    "\n",
    "For intuition, consider a population of $10,000$ people, where $100$ have the disease and $9,900$ do not. If we tested everybody in the population, we'd expect that out of the 100 diseased individuals, 95 would test positive and $5$ would test negative. Out of the $9,900$ healthy individuals, we'd expect $(0.95)(9900) \\approx 9405$ to test negative and $495$ to test positive. The $95$ TPs are far outnumbered by the $495$ FPs, so most people who test positive don't actually have the disease.\n",
    "\n",
    "**img, pg 57**\n",
    "\n",
    "\n",
    "Since all probabilities are conditional on background information, we can imagine that there is always a vertical conditioning bar, and the unconditional probability $P(A)$ is just shorthand for $P(A|B)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec11b5-5a67-418d-906b-067f0f34df76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff488821-7bcb-4de0-91c6-0c48c4d47027",
   "metadata": {},
   "source": [
    "<h4>Theorem 2.4.2 (Bayes' Rule with Extra Conditioning)</h4>\n",
    "\n",
    "Provided that $P(A \\cap E) \\gt 0$ and $P(B \\cap E) \\gt 0$, we have:\n",
    "\n",
    "$P(A|B,E) = \\frac{ P(B|A,E) P(A|E) }{ P(B|E) }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d4e54-3dc7-406b-b955-d35e11fcbe66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b17b113-97c6-4795-8b19-9dfef09af17b",
   "metadata": {},
   "source": [
    "<h4>Theorem 2.4.3 (Law of Total Probability with Extra Conditioning)</h4>\n",
    "\n",
    "Let $A_1, \\ldots, A_n$ be a partition of $S$. Provided that $P(A_i \\cap E) \\gt 0$ for all $i$, we have all the information, it does not matter whether we update sequentially or simultaneously. If we're conducting a week-long experiment, that yields data at the end of each day, we could use Bayes' rule every day to update our probabilities based on the data from that day, or update using the entire week's worth of data at the end of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718b235-3c9d-4197-9eb4-a433ee1fcf65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5ba0e2-4fe9-447b-9c08-411c8f4872c4",
   "metadata": {},
   "source": [
    "<h4>Example 2.4.4 (Random Coin Continued)</h4>\n",
    "\n",
    "In example 2.3.7, we had a fair coin and a biased coin, and we picked one at random and flipped it $3$ times.\n",
    "\n",
    "Suppose we have now seen our chosen coin land heads $3$ times. If we toss the coin a fourth time, what is the problem it will land heads once more?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Let $A$ be the event that the chosen coin lands heads $3$ times, and define a new event $H$ for the chosen coin landing heads on the fourth toss.\n",
    "\n",
    "We are interested in $P(H|A)$, and the law of total probability with extra conditioning gives us $P(H|A)$ as a weighted average of $P(H|F,A)$ and $P(H|F^C, A)$, so we can calculate the probability that we have the fair coin.\n",
    "\n",
    "$P(H|A) = P(H|F,A) P(F|A) + P(H|F^C,A) P(F^C|A) \\approx \\frac{1}{2} \\cdot 0.23 + \\frac{3}{4} \\cdot (1-0.23)$\n",
    "\n",
    "The posterior probabilities $P(F|A)$ and $P(F^C|A)$ are from our answer to example 2.3.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b693b-f826-4b4e-b5d7-4ad1c7d81e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9551d6eb-bc44-4bfe-a3e7-ba4ca406f94f",
   "metadata": {},
   "source": [
    "<h3>2.5 Independence of Events</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0424cf-ec0e-408c-9cb3-556b44857122",
   "metadata": {},
   "source": [
    "Events $A$ and $B$ are independent if:\n",
    "\n",
    "$P(A \\cap B) = P(A)P(B) or P(A|B) = P(A)$\n",
    "\n",
    "i.e., two events are independent if we can obtain the probability of their intersection by multiplying their individual probabilities, or alternatively, if learning that $B$ occurred gives us no information that would change our probability of $A$ occurring.\n",
    "\n",
    "If $A$ and $B$ are independent, then $A$ and $B^C$ are independent, $A^C$ and $B$ are indpendent, and $A^C$ and $B^C$ are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a8909-980e-4165-8fb7-725cf2e78ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "705984a1-f3bf-4a6b-8bde-89fcaa5033e0",
   "metadata": {},
   "source": [
    "<h4>Definition 2.5.6 (Independence of Many Events)</h4>\n",
    "\n",
    "For $n$ events $A_1, A_2, \\ldots, A_n$ to be independent, we require any pair to satisfy $P(A_i \\cap A_j) = P(A_i) P(A_j) P(A_k)$, for distinct $i$, $j$, and $k$.\n",
    "\n",
    "And so on... for infinitely many events, we say that they are independent if every finite subset of the events is independent.\n",
    "\n",
    "It is easy to confuse independence with conditional independence.\n",
    "- Two events can be conditionally independent given $B$, but not independent given $E^C$\n",
    "- Two events can be conditionally independent given $E$, but not independent \n",
    "- Two events can be independent, but not conditionally independent given $E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2df484-844d-46ad-bdb7-62ad71a9c204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da80a43-0db6-440b-b9a5-e4ce80e90bc9",
   "metadata": {},
   "source": [
    "<h4>Example 2.5.9 (Conditional Independence Given $E$ vs. Given $E^C$)</h4>\n",
    "\n",
    "Suppose there are two types of classes: good classes and bad classes. In good classes, hard work likely leads to a grade of $A$, whereas in bad classes, the professor randomly assigns grades. Let $G$ be the event that a class is good, $W$ be the event that you work hard, and $A$ be the event that you receive an $A$. Then $W$ and $A$ are conditionally independent given $G^C$, but not conditionally independent given $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57ae2d-8d0f-4681-be30-458ffc3efa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8981ac7f-affa-4827-ab7d-82dbdb84ec44",
   "metadata": {},
   "source": [
    "<h4>Example 2.5.10 (Conditional Independence Doesn't Imply Independence)</h4>\n",
    "\n",
    "[Returning to the scenario for 2.3.7]: \n",
    "\n",
    "<i>\"You have one fair coin and one biased coin which lands heads with probability $\\frac{3}{4}$. You pick one of the coins at random and flip it $3$ times. It lands heads all $3$ times. What is the probability that the coin you picked is the fair one? Let $F$ be the event that the fair coin is picked, and and $A$ be the event that $3$ heads are flipped.\"</i>\n",
    "\n",
    "Suppose we have chosen either a fair coin or biased coin with probability $3/4$ of $H$, but we do not know which one we have chosen. We flip the coin a number of times. Conditional on choosing the fair coin, the coin tosses are independent, with each toss having probability $1/2$ of heads. Conditional on choosing the biased coin, the tosses are independent, each with probability $3/4$ of heads.\n",
    "\n",
    "The coin tosses are not unconditionally independent, because if we don't know which coin we've chosen, observing the sequence of tosses gives us information about whether we have the fair coin.\n",
    "\n",
    "To state this formally, let $F$ be the event that we've chosen the fair coin, and let $A_1$ and $A_2$ be the events that the first and second coin tosses land heads. Conditional on $F$, $A_1$ and $A_2$ are independent, but $A_1$ and $A_2$ are not unconditionally independent because $A_1$ provides information about $A_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f845a02-4aea-4173-ac40-ab6bcade81c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81e57e14-ea17-4851-ac9c-a431910d18cf",
   "metadata": {},
   "source": [
    "<h4>Example 2.5.11 (Independence Doesn't Imply Conditional Independence)</h4>\n",
    "\n",
    "My friends Alice and Bob are the only two people who ever call me on the phone. Each day, they independently decide whether to call. Let $A$ be the event that Alice calls me next Friday and $B$ be the event that Bob calls next Friday. Assume $A$ and $B$ are unconditionally independent with $P(A) \\gt 0$ and $P(B) \\gt 0$.\n",
    "\n",
    "However, given that I receive exactly one call next Friday, $A$ and $B$ are no longer independent. The call is from Alice if and only if it is not from Bob. i.e., letting $C$ be the event that I receive exactly one call next Friday, $P(B|C) \\gt 0$ while $P(B|A,C) = 0$, so $A$ and $B$ are not conditionally independent given $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c0227-be91-4897-8d1f-40101e6244ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34665a66-07c1-443f-8c3a-a47d0d811b25",
   "metadata": {},
   "source": [
    "<h4>Example 2.5.12 (Baby Crying)</h4>\n",
    "\n",
    "**can be found in notes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d82d7-fa33-47e6-bcbe-60d7f1dafca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f779bcf-dfb5-4fd2-bc41-f96e779c500e",
   "metadata": {},
   "source": [
    "<h4>2.6 Coherency of Bayes' Rule</h4>\n",
    "\n",
    "Bayes' rule is coherent, meaning that if we receive multiple pieces of information and wish to update our probabilities to incorporate all the information, it does not matter whether we update sequentially or all at once. If we're conducting a weeklong experiment that yields data at the end of each day, we could use Bayes' rule every day to update our probabilities based on the data from that day, or using the entire week's worth of data at the end of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90621922-6a34-4e85-ad25-2feddd3020a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8baa655a-4363-4486-bdab-43bd8c15ee9c",
   "metadata": {},
   "source": [
    "<h4>Example 2.6.1 (Testing for a Rare Disease Continued)</h4>\n",
    "\n",
    "**in notes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ae796-beb9-4b85-8bc6-7b21ff5e3e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d491f-69aa-4920-8aa1-01314e18715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a477435-70fa-4cf2-ac61-b0f3d7710ea3",
   "metadata": {},
   "source": [
    "<h1>Exercises</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aeb1ec-53c9-4590-a049-e5a12cadb958",
   "metadata": {},
   "source": [
    "<h3>Conditioning on Evidence</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84af1c-ad9c-4050-ba4c-5223c8caaab4",
   "metadata": {},
   "source": [
    "<h4>Exercise 1</h4>\n",
    "\n",
    "A spam filter is designed by looking at commonly occurring phrases in spam. Suppose that $80/%$ of email is spam. In $10/%$ of the spam emails, the phrase \"free money\" is used, whereas this phrase is only used in $1/%$ of non-spam emails. A new email arrives which mentions \"free money\". What is the probability that it is spam?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Let $S$ be the event that an email is spam and $F$ be the event that an email has the \"free money\" phrase. By Bayes' rule:\n",
    "\n",
    "$P(S|F) = \\frac{ P(F|S)P(S) }{P(F)}$\n",
    "$P(S|F) = \\frac{ 0.1 \\cdot 0.8 }{ 0.1 \\cdot 0.8 + 0.01 \\cdot 0.2 }$\n",
    "$P(S|F) = \\frac{80/1000}{82/1000} = \\frac{80}{82} \\approx 0.9756$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c3e3e-69aa-468a-a7e6-f9ae74c2fe63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a985e0a3-b51d-47d9-9f15-267fabd5f71a",
   "metadata": {},
   "source": [
    "<h4>Exercise 2</h4>\n",
    "\n",
    "A woman is pregnant with twin boys. Twins may be either identical or fraternal. In general, $\\frac{1}{3}$ or twins born are identical. Fraternal twins may or may not be of the same sex (identical twins cannot be). What is the probability that the woman's twins are identical?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "$P(Identical|BB) = \\frac{ P(BB|Identical)P(Identical) }{P(BB)}$\n",
    "\n",
    "$P(Identical|BB) = \\frac{ \\frac{1}{2} \\cdot \\frac{1}{3} }{ \\frac{1}{2} \\cdot \\frac{1}{3} + \\frac{1}{4} \\cdot \\frac{2}{3} } = \\frac{1}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fcd142-1108-4771-b8ec-f750e3d36e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cbb3463-3366-4317-a06a-bcce89a5dace",
   "metadata": {},
   "source": [
    "<h4>Exercise 22</h4>\n",
    "\n",
    "A bag contains one marble which is either green or blue, with equal probabilities. A green marble is put in the bag (so there are $2$ marbles now), and then a random marble is taken out. The marble taken out is green. What is the probability that the remaining marble is also green?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Let $A$ be the event that the initial marble is green, $B$ be the event that the removed marble is green, and $C$ be the event that the remaining marble is green. We need to find $P(C|B)$, and one natural way is to condition on whether the initial marble is given.\n",
    "\n",
    "$P(C|B) = P(C|B,A) P(A|B) + P(C|B,A^C) P(A^C|B)$\n",
    "$P(C|B) = 1 P(A|B) + 0 P(A^C|B)$\n",
    "\n",
    "To find $P(A|B)$, use Bayes' rule.\n",
    "\n",
    "$P(A|B) = \\frac{ P(B|A) P(A) }{P(B)}$\n",
    "\n",
    "$P(A|B) = \\frac{ \\frac{1}{2} }{ P(B|A) P(A) + P(B|A^C) P(A^C) }$\n",
    "\n",
    "$P(A|B) = \\frac{ \\frac{1}{2} }{ \\frac{1}{2} + \\frac{1}{4} } = \\frac{2}{3}$\n",
    "\n",
    "So $P(C|B) = \\frac{2}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c2eb4-44c2-4d55-8291-c6595338c6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4ad2f8e-36e8-42e0-a5a5-5e3329b3b411",
   "metadata": {},
   "source": [
    "<h4>Exercise 23</h4>\n",
    "\n",
    "Let $G$ be the event that a certain individual is guilty of a certain robbery. In gathering evidence, it is learned that an event $E_1$ occurred, and a little later it is also learned that another event $E_2$ also occurred. Is it possible that individually, these pieces of evidence increase the chance of guilt (so $P(G|E) \\gt P(G)$ and $P(G|E_2) \\gt P(G))$, but together they decrease the chance of guilt (so $P(G|E_1, E_2) \\lt P(G))$?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Yes, it is possible to have two events which separately provide evidence in favor of $G$, yet which together preclude $G$.\n",
    "\n",
    "For example, suppose that the crime was committed between 1pm and 3pm on a certain day. Let $E_1$ be the event that the suspect was at a nearby coffeeshop from 1pm to 2pm that day, and $E_2$ be the event that the suspect was at the nearby coffeeshop from 2pm to 3pm that day.\n",
    "\n",
    "Then $P(G|E_1) \\gt P(G)$ and $P(G|E_2) \\gt P(G)$, yet $P(G|E_1 \\cap E_2) \\lt P(G)$, as being in the coffeehouse from 1pm to 3pm gives an alibi for the whole time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71474610-7ebd-45d8-b075-4293ffc2d7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9740fc6c-39b4-47d7-94ad-664f86cec90d",
   "metadata": {},
   "source": [
    "<h4>Exercise 25</h4>\n",
    "\n",
    "A crime is committed by one of two suspects, A and B. Initially, there is equal evidence against both of them. In further investigation, it is found that the guilty party had a blood type found in $10\\%$ of the population. Suspect $A$ does match this blood type, whereas the blood type of suspect $B$ is unknown.\n",
    "\n",
    "<b>Part A:</b>\n",
    "\n",
    "Given this new information, what is the probability that $A$ is the guilty party?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Let $M$ be the event that $A$'s blood type matches the guilty party's. Let $A$ mean $A$ is guilty, and $B$ mean $B$ is guilty. By Bayes' rule:\n",
    "\n",
    "$P(A|M) = \\frac{ P(M|A)P(A) }{ P(M|A)P(A) + P(M|B)P(B) }$\n",
    "\n",
    "$P(A|M) = \\frac{ \\frac{1}{2} }{ \\frac{1}{2} + \\left( \\frac{1}{10} \\right) \\left( \\frac{1}{2} \\right) } = \\frac{10}{11}$\n",
    "\n",
    "We have $P(M|B) = \\frac{1}{10}$ since, given that $B$ is guilty, the probability that $A$'s blood type matches the guilty party's is the same probability as for the general population.\n",
    "\n",
    "\n",
    "<b>Part B:</b>\n",
    "\n",
    "What is the probability that $B$'s blood type matches that found at the scene?\n",
    "\n",
    "Let $C$ be the event that $B$'s blood type matches, and condition on whether $B$ is guilty. This gives:\n",
    "\n",
    "$P(C|M) = P(C|M,A) P(A|M) + P(C|M,B) P(B|M)$\n",
    "\n",
    "$P(C|M) = \\frac{1}{10} \\cdot \\frac{10}{11} + \\frac{1}{11} = \\frac{2}{11}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b2b55-2e3e-4d50-bc94-5927006a1ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2fc9f3a-696e-40b7-b0d0-2f00fd98031a",
   "metadata": {},
   "source": [
    "<h4>Exercise 26</h4>\n",
    "\n",
    "Bob installs two anti-spam programs. An email arrives, which is either legitmate (event $L$) or spam (event $L^C$), and which program $j$ marks as legitimate (event $M_j$) or spam (event $M_j^C$). Assume that $10\\%$ of Bob's email is legitimate and that the two programs are each $90\\%$ accurate, i.e. $P(M_j|L) = P(M_j^C|L^C) = 0.9$. Assume that given whether an email is spam, the two program's outputs are conditionally independent.\n",
    "\n",
    "<b>Part A:</b>\n",
    "\n",
    "Find the probability that the email is legitimate, given that the first program marks it as legitimate.\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "$P(L|M_1) = \\frac{ P(M_1|L) P(L) }{P(M_1)}$\n",
    "\n",
    "$P(L|M_1) = \\frac{ \\frac{9}{10} \\cdot \\frac{1}{10} }{ \\frac{9}{10} \\cdot \\frac{1}{10} + \\frac{1}{10} \\cdot \\frac{9}{10} } = \\frac{1}{2}$\n",
    "\n",
    "\n",
    "<b>Part B:</b>\n",
    "\n",
    "Find the problem that the email is legitimate, given that both programs mark it as legitimate.\n",
    "\n",
    "$P(L|M_1, M_2) = \\frac{ P(M_1,M_2|L) P(L) }{ P(M_1,M_2) }$\n",
    "\n",
    "$P(L|M_1, M_2) = \\frac{ \\left( \\frac{9}{10} \\right) \\cdot \\frac{1}{10} }{ \\left( \\frac{9}{10} \\right)^2 \\cdot \\frac{1}{10} + \\left( \\frac{1}{10} \\right) \\frac{9}{10} } = \\frac{9}{10}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b2b95-bc40-4027-8741-2feb9284206e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "618d2632-d518-440f-80b5-ec6f760a209c",
   "metadata": {},
   "source": [
    "<h3>Independence and Conditional Independence</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4cff9-1aa7-4d47-8afb-5a2a1157b17e",
   "metadata": {},
   "source": [
    "<h4>Exercise 30</h4>\n",
    "\n",
    "A family has 3 children, $A$, $B$, and $C$.\n",
    "\n",
    "<b>Part A:</b>\n",
    "\n",
    "Discuss wehether the event \"A is older than B\" is independent of the event \"A is older than C\".\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "They are not independent. Knowing $A$ is older than B makes it more likely that $A$ is older than $C$, as the only way that A can be younger than $C$ is then if the birth order $ABC$ and $ACB$ are both compatible with $A$ being older than $B$.\n",
    "\n",
    "To make this more intuitive, think of an extreme case where there are $100$ children instead of $3$, $A_1, \\ldots, A_{100}$. Given that $A_1$ is older than all of $A_2, A_3, \\ldots, A_{99}$, it's clear that $A_1$ is very old (relatively), whereas there isn't evidence about where $A_{100}$ fits into the birth order.\n",
    "\n",
    "<b>Part B:</b>\n",
    "\n",
    "Find the probability that $A$ is older than $B$, given that $A$ is older than $C$.\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Writing $x \\gt y$ to mean that $x$ is older than $y$.\n",
    "\n",
    "$P(A \\gt B | A \\gt C) = \\frac{ P(A \\gt B, A \\gt C) }{ P(A \\gt C) } = \\frac{1/3}{1/2} = \\frac{2}{3}$\n",
    "\n",
    "since $P(A \\gt B, A \\gt C) = P(\\text{A is oldest}) = \\frac{1}{3}$. Unconditionally, any of the three children is likely to be oldest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630fde7-58ef-4828-b4ff-c4f2e7babe9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a162c966-6d41-4a3f-b834-7a81c2e11eb0",
   "metadata": {},
   "source": [
    "<h4>Exercise 31</h4>\n",
    "\n",
    "Is it possible that an event is independent of itself?\n",
    "\n",
    "Answer:\n",
    "\n",
    "If $A$ is independent of itself, $P(A) = P(A \\cap A) = P(A)^2$, therefore this is only possible in the extreme cases where $P(A)=0$ or $P(A)=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e95e76-2b8a-4a93-a2a7-9e89368d56bf",
   "metadata": {},
   "source": [
    "<h4>Exercise 35</h4>\n",
    "\n",
    "You are going to play two games of chess with an opponent whom you have never played against before. The opponent is equally likely to be a beginner, intermediate, or master, and depending on which, your chances of winning a game are $90\\%$, $50\\%$, and $30\\%$ respectively.\n",
    "\n",
    "<b>Part A:</b>\n",
    "\n",
    "What is your probability of winning the game?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "$P(W_1) = (0.9 + 0.5 + 0.3) / 3 = 17/30$\n",
    "\n",
    "\n",
    "<b>Part B:</b>\n",
    "\n",
    "You won the first game. What is the probability that you will also win the second?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "$P(W_2|W_1) = \\frac{ P(W_2,W_1) }{P(W_1)}$\n",
    "\n",
    "The denominator is known from part $A$ while the numerator can be found by conditioning on the skill level of the opponent.\n",
    "\n",
    "$P(W_1, W_2) = \\frac{1}{3} P(W_1, W_2 | beginner) + \\frac{1}{3} P(W_1, W_2 | intermediate) + \\frac{1}{3} P(W_1, W_2 | master)$\n",
    "\n",
    "Since $W_1$ and $W_2$ are conditionally independent, given the skill of the opponent.\n",
    "\n",
    "$P(W_1, W_2) = (0.9^2 + 0.5^2 + 0.3^2) / 3 = 23/60$\n",
    "\n",
    "$P(W_2, W_1) = \\frac{23/60}{17/30} = \\frac{23}{34}$\n",
    "\n",
    "\n",
    "<b>Part C:</b>\n",
    "\n",
    "Explain the distinction between assuming that the outcomes of the games are independent and assuming that they are conditionally independent given the opponent's skill level. Which of these assumptions seems more reasonable, and why?\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Independent means that knowing one game's outcome gives no information about the other game's outcome, while conditional independence is the same statement where all probabilities are conditioned on the opponent's skill level.\n",
    "\n",
    "Conditional independence given the opponent's skill level is a more reasonable assumption. Winning the first game gives information about the opponent's skill level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e91b7-c7f4-4cba-9261-f8831f7ca52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d72d4408-251c-47b3-87e3-7c0e5b9b7e4d",
   "metadata": {},
   "source": [
    "<h3>First-Step Analysis and Gambler's Ruin Exercies</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d98d6d-9ffc-4f50-b998-8e9dd06f002c",
   "metadata": {},
   "source": [
    "<h4>Exercise 42</h4>\n",
    "\n",
    "A fair die is rolled repeatedly, and a running total is kept. Let $p_n$ be the probability that the running total is ever exactly $n$? Assume the die will always be rolled enough times so that the running total will eventually exceed $n$, but may or may not ever equal $n$.\n",
    "\n",
    "<b>Part A:</b>\n",
    "\n",
    "Write a recursive equation for $p_n$ (relating $p_n$ to earlier terms $p_k$). Your equation should be true for all positive integers $n$. i.e., give a definition of $p_0$ and $p_k$ for $k \\lt 0$ so that the recursive equation is true for small values of $x$.\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "We will find something to condition on to reduce the case of interact to earlier, simpler cases. This is first step analysis.\n",
    "\n",
    "Let $p_n$ be the probability that the running total is ever exactly $n$. If, for example, the first throw is a $3$, then the probability of reaching $n$ exactly is $p_{n-3}$ since starting from that point, we need to get a total of $n-3$. So,\n",
    "\n",
    "$p_n = \\frac{1}{6}(p_{n-1}, p_{n-2}, \\ldots, p_{n-6})$\n",
    "\n",
    "\n",
    "<b>Part B:</b>\n",
    "\n",
    "Find $p_7$.\n",
    "\n",
    "<i>Answer:</i>\n",
    "\n",
    "Using the recursive equation in part $A$, we have:\n",
    "\n",
    "$p_1 = \\frac{1}{6}$\n",
    "\n",
    "$p_2 = \\frac{1}{6} \\left( 1 + \\frac{1}{6} \\right)$\n",
    "\n",
    "$p_3 = \\frac{1}{6} \\left( 1 + \\frac{1}{6} \\right)^2$\n",
    "\n",
    "$\\ldots$\n",
    "\n",
    "$p_6 = \\frac{1}{6} \\left( 1 + \\frac{1}{6} \\right)^5$\n",
    "\n",
    "Hence:\n",
    "\n",
    "$p_7 = \\frac{1}{6} (p_1 + p_2 + \\ldots + p_6)$\n",
    "\n",
    "$p_7 = \\frac{1}{6} \\left( \\left( 1 + \\frac{1}{6} \\right)^6 - 1 \\right) \\approx 0.2536$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
